data "aws_iam_policy_document" "lambda_assume_role" {
  statement {
    actions = ["sts:AssumeRole"]
    principals {
      type        = "Service"
      identifiers = ["lambda.amazonaws.com"]
    }
  }
}

locals {
  destination_object_arns = flatten([
    for path in var.destination_paths : [
      "arn:aws:s3:::${var.destination_bucket_name}/${path}",
      # "arn:aws:s3:::${var.destination_bucket_name}/${path}*"
    ]
  ])
}

resource "aws_iam_role" "lambda_role" {
  name               = "${var.function_name}-role"
  assume_role_policy = data.aws_iam_policy_document.lambda_assume_role.json
  tags               = var.tags
}

resource "aws_iam_role_policy_attachment" "lambda_basic_execution" {
  role       = aws_iam_role.lambda_role.name
  policy_arn = "arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole"
}

resource "aws_secretsmanager_secret" "smartling_secret" {
  # checkov:skip=CKV_AWS_149: Using default KMS key for encryption is sufficient for this secret
  # checkov:skip=CKV2_AWS_57: Secret is static user credential, rotation not managed by this module
  name                    = "${var.function_name}-smartling-secret"
  description             = "Smartling User Secret for GTFS translation"
  recovery_window_in_days = var.is_temporary ? 0 : 30
  tags                    = var.tags
}

resource "aws_iam_role_policy" "lambda_permissions" {
  name = "GTFSTranslatorPermissions"
  role = aws_iam_role.lambda_role.id

  policy = jsonencode({
    Version = "2012-10-17"
    Statement = concat(
      [
        {
          Action = [
            "secretsmanager:GetSecretValue"
          ]
          Effect   = "Allow"
          Resource = aws_secretsmanager_secret.smartling_secret.arn
        },
        {
          Action = [
            "s3:GetObject",
            "s3:PutObject"
          ]
          Effect   = "Allow"
          Resource = local.destination_object_arns
        },
        {
          Action = [
            "s3:ListBucket"
          ]
          Effect   = "Allow"
          Resource = "arn:aws:s3:::${var.destination_bucket_name}"
        }
      ],
      var.trigger.type == "s3" ? [
        {
          Action = ["s3:GetObject"]
          Effect = "Allow"
          Resource = [
            "arn:aws:s3:::${var.trigger.bucket_name}/${var.trigger.prefix != null ? var.trigger.prefix : ""}",
            "arn:aws:s3:::${var.trigger.bucket_name}/${var.trigger.prefix != null ? var.trigger.prefix : ""}*"
          ]
        }
      ] : []
    )
  })
}

resource "aws_cloudwatch_log_group" "lambda_logs" {
  # checkov:skip=CKV_AWS_158: Log encryption with CMK not required for this task
  # checkov:skip=CKV_AWS_338: 14 days retention is sufficient and cost-effective for this project
  name              = "/aws/lambda/${var.function_name}"
  retention_in_days = var.is_temporary ? 1 : 14
  tags              = var.tags
}

resource "aws_lambda_function" "translation_function" {
  # checkov:skip=CKV_AWS_117: Lambda does not require VPC as it only accesses public APIs and AWS services
  # checkov:skip=CKV_AWS_116: DLQ not required for this specific non-critical background task
  # checkov:skip=CKV_AWS_115: Concurrent execution limit handled by caller/triggering frequency
  # checkov:skip=CKV_AWS_272: Code signing not currently used in this pipeline
  # checkov:skip=CKV_AWS_173: Environment variables do not contain sensitive data (secrets are in Secrets Manager)
  # checkov:skip=CKV_AWS_50: X-Ray tracing not required for this simple translation task
  function_name                  = var.function_name
  role                           = aws_iam_role.lambda_role.arn
  handler                        = "gtfs_translation.lambda_handler.lambda_handler"
  runtime                        = "python3.13"
  timeout                        = var.lambda_timeout
  memory_size                    = var.lambda_memory_size
  architectures                  = var.lambda_architectures
  reserved_concurrent_executions = var.reserved_concurrent_executions

  # The function.zip is generated by 'mise run build'
  filename         = "${path.module}/../function.zip"
  source_code_hash = fileexists("${path.module}/../function.zip") ? filebase64sha256("${path.module}/../function.zip") : null

  environment {
    variables = {
      SMARTLING_USER_ID         = var.smartling_user_id
      SMARTLING_USER_SECRET_ARN = aws_secretsmanager_secret.smartling_secret.arn
      SMARTLING_ACCOUNT_UID     = var.smartling_account_uid
      SMARTLING_PROJECT_ID      = var.smartling_project_id
      SMARTLING_JOB_NAME_TEMPLATE = coalesce(
        var.smartling_job_name_template,
        var.function_name
      )
      SOURCE_URL = var.trigger.source_url != null ? var.trigger.source_url : ""
      DESTINATION_BUCKET_URLS = join(",", [
        for path in var.destination_paths : "s3://${var.destination_bucket_name}/${path}"
      ])
      TARGET_LANGUAGES = join(",", var.target_languages)
      LOG_LEVEL        = var.log_level
    }
  }

  depends_on = [
    aws_cloudwatch_log_group.lambda_logs
  ]

  tags = var.tags
}

# --- Trigger Configuration ---

# Cron Trigger
resource "aws_cloudwatch_event_rule" "cron" {
  count               = var.trigger.type == "cron" ? 1 : 0
  name                = "${var.function_name}-cron"
  description         = "Schedule for GTFS alerts translation"
  schedule_expression = var.trigger.schedule_expression
  tags                = var.tags
}

resource "aws_cloudwatch_event_target" "cron" {
  count = var.trigger.type == "cron" ? 1 : 0
  rule  = aws_cloudwatch_event_rule.cron[0].name
  arn   = aws_lambda_function.translation_function.arn
}

resource "aws_lambda_permission" "cron" {
  count         = var.trigger.type == "cron" ? 1 : 0
  statement_id  = "AllowExecutionFromCloudWatch"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.translation_function.function_name
  principal     = "events.amazonaws.com"
  source_arn    = aws_cloudwatch_event_rule.cron[0].arn
}

# S3 Trigger
resource "aws_lambda_permission" "s3" {
  count         = var.trigger.type == "s3" ? 1 : 0
  statement_id  = "AllowExecutionFromS3Bucket"
  action        = "lambda:InvokeFunction"
  function_name = aws_lambda_function.translation_function.function_name
  principal     = "s3.amazonaws.com"
  source_arn    = "arn:aws:s3:::${var.trigger.bucket_name}"
}

resource "aws_s3_bucket_notification" "bucket_notification" {
  count  = var.trigger.type == "s3" ? 1 : 0
  bucket = var.trigger.bucket_name

  lambda_function {
    lambda_function_arn = aws_lambda_function.translation_function.arn
    events              = ["s3:ObjectCreated:*"]
    filter_prefix       = var.trigger.prefix
  }

  depends_on = [aws_lambda_permission.s3]
}
